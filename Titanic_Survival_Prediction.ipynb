{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2, l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reading Data\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Printind Data Info\n",
    "print(data.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Survived Column as Labels\n",
    "train_labels = np.array(data['Survived']).astype('float32')\n",
    "\n",
    "validation_labels = train_labels[:200]\n",
    "train_labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bunny/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-4-bbc13df0520c>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Sex'] = train_data['Sex'].replace(('male','female'), (1,0))\n",
      "<ipython-input-4-bbc13df0520c>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['Sex'] = test_data['Sex'].replace(('male','female'), (1,0))\n",
      "<ipython-input-4-bbc13df0520c>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Embarked'] = train_data['Embarked'].replace(('S','C','Q'), (0,1,2))\n",
      "<ipython-input-4-bbc13df0520c>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['Embarked'] = test_data['Embarked'].replace(('S','C','Q'), (0,1,2))\n"
     ]
    }
   ],
   "source": [
    "# Selecting Features which have impacted the status of Survival\n",
    "train_data = data[['Pclass', 'Sex', 'Fare', 'Age', 'Embarked']]\n",
    "test_data = test[['Pclass', 'Sex', 'Fare', 'Age', 'Embarked']]\n",
    "\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace = True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(), inplace = True)\n",
    "\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace = True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace = True)\n",
    "\n",
    "train_data['Embarked'].fillna('S', inplace = True)\n",
    "test_data['Embarked'].fillna('S', inplace = True)\n",
    "\n",
    "train_data['Sex'] = train_data['Sex'].replace(('male','female'), (1,0))\n",
    "test_data['Sex'] = test_data['Sex'].replace(('male','female'), (1,0))\n",
    "\n",
    "train_data['Embarked'] = train_data['Embarked'].replace(('S','C','Q'), (0,1,2))\n",
    "test_data['Embarked'] = test_data['Embarked'].replace(('S','C','Q'), (0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data).astype('float32')\n",
    "train_data.shape\n",
    "\n",
    "validation_data = train_data[:200]\n",
    "train_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 5), (891,), (200, 5), (200,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape, validation_data.shape, validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, dtype=None):\n",
    "    \n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, dtype=None):\n",
    "    \n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "\n",
    "def DeepLearningModel(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(input_shape))\n",
    "    \n",
    "    model.add(Dense(8, activation='relu', kernel_initializer=initialize_weights, bias_initializer=initialize_bias, kernel_regularizer=l1(2e-4)))\n",
    "    \n",
    "    model.add(Dense(16, activation='relu', kernel_initializer=initialize_weights, bias_initializer=initialize_bias, kernel_regularizer=l1(2e-4)))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu', kernel_initializer=initialize_weights, bias_initializer=initialize_bias, kernel_regularizer=l1(2e-4)))\n",
    "    \n",
    "    model.add(Dense(16, activation='relu', kernel_initializer=initialize_weights, bias_initializer=initialize_bias, kernel_regularizer=l1(2e-4)))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=initialize_weights, bias_initializer=initialize_bias, kernel_regularizer=l1(2e-4)))    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.5064\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.6239\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6007\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6401\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.6307 - accuracy: 0.6319\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.6685\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7037\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7003\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7313\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7254\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7615\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7428\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7722\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7731\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7413\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8199\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7883\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7591\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7883\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7975\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7658\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7607\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7922\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7859\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.8168\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7998\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7743\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7782\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7854\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8128\n"
     ]
    }
   ],
   "source": [
    "lr = 0.006\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "optimizer = Adam(lr)\n",
    "\n",
    "model = DeepLearningModel((5))\n",
    "print(model.summary())\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# model = GradientBoostingClassifier()\n",
    "# model = model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49847412109375, 0.7350000143051147]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_data, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(history):\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)\n",
    "pred = np.round(pred)\n",
    "pred = list(map(int,np.reshape(pred, (pred.shape[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Survived\": pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./output/titanic_survivors.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
